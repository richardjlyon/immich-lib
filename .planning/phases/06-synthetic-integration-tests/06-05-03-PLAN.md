---
phase: 06-synthetic-integration-tests
plan: 03
type: execute
---

<objective>
Implement conflict detection and edge case integration tests, then verify full test suite.

Purpose: Complete test coverage for all fixture scenarios and validate the integration test suite works end-to-end.
Output: Integration tests for F1-F7 (conflicts) and X1-X5, X7, X9-X11 (edge cases), plus human verification.

Note: X6 (HEIC) and X8 (RAW) were removed in 06-05.2-01 - cannot generate valid files without proprietary encoders.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/06-synthetic-integration-tests/06-05-01-SUMMARY.md
@.planning/phases/06-synthetic-integration-tests/06-05-02-SUMMARY.md
@.planning/phases/06-synthetic-integration-tests/06-05.2-01-SUMMARY.md
@tests/fixtures/MANIFEST.md

**Prior decisions:**
- GPS conflict threshold 0.0001 deg (~11m tolerance)
- String normalization lowercase+trim for conflict detection

**Test scenarios (32 total, 31 with duplicate groups):**
- F1-F7: Conflict detection (GPS, timezone, camera, time)
- X1-X5, X7, X9-X11: Edge cases (single asset, large groups, video, PNG, unicode, dates)
- Note: X6 (HEIC) and X8 (RAW) removed - cannot generate without proprietary encoders
</context>

<tasks>

<task type="auto">
  <name>Task 1: Conflict detection tests (F1-F7)</name>
  <files>tests/integration/conflict_tests.rs</files>
  <action>
Create integration tests for conflict scenarios:

1. Create `conflict_tests.rs` with:
   - Test function `test_conflict_detection()`
   - For each F scenario (f1-f7):
     - Load manifest
     - Find matching duplicate group
     - Assert winner matches expected_winner
     - Check conflict detection in scored output:
       - F1: Should have GPS conflict (London vs Paris)
       - F2: Should NOT have GPS conflict (within threshold)
       - F3: Should have timezone conflict
       - F4: Should have camera conflict
       - F5: Should have capture time conflict
       - F6: Should have multiple conflicts
       - F7: Should have NO conflicts

2. Conflict assertions:
   ```rust
   // Check if group has specific conflict type
   fn has_conflict_type(group: &ScoredDuplicateGroup, conflict_type: &str) -> bool {
       group.conflicts.iter().any(|c| c.conflict_type == conflict_type)
   }

   // F1: GPS conflict expected
   assert!(has_conflict_type(group, "gps"), "F1 should have GPS conflict");

   // F2: NO GPS conflict (within threshold)
   assert!(!has_conflict_type(group, "gps"), "F2 should NOT have GPS conflict");
   ```

3. Use ScoredDuplicateGroup.conflicts field from scoring module
  </action>
  <verify>cargo test --test integration -- --ignored includes conflict tests</verify>
  <done>F1-F7 conflict detection tests pass with correct conflict identification</done>
</task>

<task type="auto">
  <name>Task 2: Edge case tests (X1-X5, X7, X9-X11)</name>
  <files>tests/integration/edge_case_tests.rs</files>
  <action>
Create integration tests for edge case scenarios:

1. Create `edge_case_tests.rs` with:
   - Test function `test_edge_cases()`
   - For each X scenario (x1-x5, x7, x9-x11):
     - Load manifest
     - Find matching duplicate group (if expected to exist)
     - Assert winner matches expected_winner (where applicable)

2. Edge case handling:
   - X1: Single asset - will NOT appear in duplicates (expected)
   - X2: Large group (12 duplicates) - verify all 12 are in group
   - X3: Large file - verify dimensions parsed correctly
   - X4: Special characters in filename - verify filename matching works
   - X5: Video duplicates - verify video handling
   - X7: PNG format - verify format handling
   - X9: Unicode in description - verify unicode handling
   - X10: Very old date (1985) - verify date parsing
   - X11: Future date (2030) - verify date handling

3. Single asset group (X1) will not appear in duplicates - that's expected behavior

4. Note: X6 (HEIC) and X8 (RAW) were removed - skip these scenarios
  </action>
  <verify>cargo test --test integration -- --ignored includes edge case tests</verify>
  <done>Edge case tests handle all remaining X scenarios appropriately</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete integration test suite covering all 32 fixture scenarios</what-built>
  <how-to-verify>
1. Ensure Docker is running with fixtures seeded:
   ```bash
   cd tests/docker
   # If needed: ./teardown.sh && ./bootstrap.sh && ./seed-fixtures.sh
   ```

2. Run the full integration test suite:
   ```bash
   cargo test --test integration -- --ignored --nocapture
   ```

3. Review the output:
   - Check how many scenarios were found in duplicates (expect 31 - all except X1)
   - Check which tests passed vs warned
   - Note any assertion failures

4. Expected behavior:
   - All W (8) and C (8) scenarios should find their duplicate groups
   - All F (7) scenarios should find groups with correct conflict detection
   - X1 will NOT appear in duplicates (single asset - expected)
   - X2-X5, X7, X9-X11 should find groups
   - Winner selection should match expected_winner in all found groups

5. If tests fail, review which scenarios failed and why
  </how-to-verify>
  <resume-signal>Type "approved" if tests work correctly, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] All integration test files compile
- [ ] `cargo test --test integration -- --ignored` runs without panics
- [ ] Winner selection correct for found duplicate groups
- [ ] Conflict detection works as expected
- [ ] Edge cases handled gracefully
</verification>

<success_criteria>
- Integration tests cover all 32 fixture scenarios (X6/X8 removed)
- 31 duplicate groups detected and tested (X1 has no group - expected)
- Conflict detection correctly identifies/excludes conflicts per F1-F7 specs
- Edge cases (X2-X5, X7, X9-X11) handled correctly
- Human verification confirms test suite works end-to-end
</success_criteria>

<output>
After completion, create `.planning/phases/06-synthetic-integration-tests/06-05-03-SUMMARY.md`
</output>
